{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简介\n",
    "- [self2self](https://openaccess.thecvf.com/content_CVPR_2020/papers/Quan_Self2Self_With_Dropout_Learning_Self-Supervised_Denoising_From_Single_Image_CVPR_2020_paper.pdf)是利用单张图片就可以进行去噪\n",
    "- 利用伯努利采样得到的图片作为去噪网络输入伯努利采样的补集作为预测目标\n",
    "- 仅在伯努利采样补集上计算损失\n",
    "- 在伯努利采样概率0.3下运行100000次效果比较好\n",
    "- 论文中的网络结构使用了partial convolution和dropout，dropout比较关键\n",
    "- 掩码必须每个channel都不同效果才最好\n",
    "- 图片输入时调用toTensor即可，不要进行标准化\n",
    "- 不要使用randomFlip，不要使用多张图片，否则会破坏分布\n",
    "- 如何腐蚀noise图像是一个需要探讨的话题\n",
    "- L1 loss没有L2 loss抗噪，很容易出现彩块\n",
    "- 学习率不能过大，否则会很快学到噪声，并且adamw会梯度爆炸\n",
    "- 从雪坑的质感看，网络学到的近似于溶解\n",
    "- 加式残差学习在监督学习中效果很好，在无监督学习中起负面作用，直接加法的特点是高频特征学得很快，建议用拼接代替加法实现残差。\n",
    "- 神经网络对噪声的阻抗来自于伯努利抽样、池化层、cat操作\n",
    "- 采样概率过小或者过大都会加剧模糊\n",
    "- 第一层和最后一层的通道数对结果影响非常大，建议输入通道数至少达到64\n",
    "- 不用sigmoid函数图像会暗很多,清晰度也下降，但不管这样去噪后图片亮度都会偏暗\n",
    "- 网络越深色偏越大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0+cu113\n",
      "cuda\n",
      "/root/autodl-tmp/facial landmarks denoise\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tnrange\n",
    "\n",
    "print(torch.__version__)\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "if device=='cuda':\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from torch import tensor\n",
    "with open('data/4.txt','r') as fp:\n",
    "    data=tensor(json.load(fp),device=device)\n",
    "noisyxy=data[:,:,0:2].flatten(1,2).permute([1,0])\n",
    "noisyz=data.select(2,2).permute([1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "\n",
    "class HourGlassCNNBlock(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,activation=nn.LeakyReLU(0.1)):\n",
    "        super(HourGlassCNNBlock,self).__init__()\n",
    "        layers=[]\n",
    "        layers.append(nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1,device='cuda'))\n",
    "        if activation:layers.append(activation)\n",
    "        self.main=nn.Sequential(*layers)\n",
    "    def forward(self,x):\n",
    "        return self.main(x)#channel不同不能进行残差学习\n",
    "\n",
    "class XYDenoiser(nn.Module):\n",
    "    def __init__(self,noisyxy):\n",
    "        super(XYDenoiser,self).__init__()\n",
    "        self.b1=HourGlassCNNBlock(478*2,2**10)\n",
    "        self.b2=HourGlassCNNBlock(2**10,2**11)\n",
    "\n",
    "        self.b3=HourGlassCNNBlock(2**11,2**10)\n",
    "        self.b4=HourGlassCNNBlock(2**11,2**10)\n",
    "        self.b5=HourGlassCNNBlock(2**10,478*2,None)\n",
    "        self.b6=HourGlassCNNBlock(478*4,478*2,nn.Sigmoid())\n",
    "\n",
    "        self.noisyxy=noisyxy\n",
    "    def forward(self,x):\n",
    "        b1=self.b1(x)\n",
    "        b2=self.b2(b1)\n",
    "        b3=self.b3(b2)\n",
    "        b4=self.b4(torch.cat((b3,b1)))\n",
    "        b5=self.b5(b4)\n",
    "        b6=self.b6(torch.cat((b5,x)))\n",
    "\n",
    "        return b6.squeeze(0)\n",
    "class ZDenoiser(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ZDenoiser,self).__init__()\n",
    "        self.b1=HourGlassCNNBlock(478,2**9)\n",
    "        self.b2=HourGlassCNNBlock(2**9,2**10)\n",
    "\n",
    "        self.b3=HourGlassCNNBlock(2**10,2**9)\n",
    "        self.b4=HourGlassCNNBlock(2**10+478,2**9)\n",
    "        self.b5=HourGlassCNNBlock(2**9,478,None)\n",
    "        self.b6=HourGlassCNNBlock(478*2,478,None)\n",
    "\n",
    "    def forward(self,x):\n",
    "        b1=self.b1(x)\n",
    "        b2=self.b2(b1)\n",
    "        b3=self.b3(b2)\n",
    "        b4=self.b4(torch.cat((b3,b1,x),dim=0))\n",
    "        b5=self.b5(b4)\n",
    "        b6=self.b6(torch.cat((b5,x),dim=0))\n",
    "\n",
    "        return b6.squeeze(0)\n",
    "import math\n",
    "from torch import tensor, cat, zeros, ones,  randperm, bernoulli, full\n",
    "\n",
    "# percent:percent of zeros in mask\n",
    "def create_mask(channels=478*2, length=30*30,  percent=0.2, probability=0.25, mode='bernoulli', device='cuda'):\n",
    "    if mode == 'percent':\n",
    "        num = length*channels\n",
    "        num_zeros = math.floor(num*percent)\n",
    "        num_ones = num-num_zeros\n",
    "        x = cat((zeros(num_zeros, device=device), ones(num_ones, device=device)))\n",
    "        x = x[randperm(num)]\n",
    "        x = x.view((channels,length))\n",
    "        return x\n",
    "    elif mode == 'bernoulli':\n",
    "        return bernoulli(full((channels,length), 1-probability, device=device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim,zeros\n",
    "xymodel = XYDenoiser(noisyxy=noisyxy).to(device=device)\n",
    "zmodel=ZDenoiser().to(device=device)\n",
    "xyoptimizer = optim.RAdam(xymodel.parameters(),lr=5*1e-5)\n",
    "zoptimizer=optim.RAdam(zmodel.parameters(),lr=2.5*1e-5)\n",
    "mse = nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d386e4670ab74937a4fbbb69ed714f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1000, loss = 9193.6320\n",
      "iteration 2000, loss = 7845.5381\n",
      "iteration 3000, loss = 6558.2179\n",
      "iteration 4000, loss = 5617.9442\n",
      "iteration 5000, loss = 4874.5330\n",
      "iteration 6000, loss = 4302.8593\n",
      "iteration 7000, loss = 3802.5104\n",
      "iteration 8000, loss = 3389.6826\n",
      "iteration 9000, loss = 3036.1610\n",
      "iteration 10000, loss = 2723.6650\n",
      "iteration 11000, loss = 2436.3210\n",
      "iteration 12000, loss = 2203.0767\n",
      "iteration 13000, loss = 1992.2141\n",
      "iteration 14000, loss = 1796.0476\n",
      "iteration 15000, loss = 1610.9353\n",
      "iteration 16000, loss = 1465.5154\n",
      "iteration 17000, loss = 1336.7856\n",
      "iteration 18000, loss = 1207.4728\n",
      "iteration 19000, loss = 1123.1512\n",
      "iteration 20000, loss = 1003.5913\n",
      "iteration 21000, loss = 913.7438\n",
      "iteration 22000, loss = 835.4478\n",
      "iteration 23000, loss = 765.1262\n",
      "iteration 24000, loss = 713.9108\n",
      "iteration 25000, loss = 660.2539\n",
      "iteration 26000, loss = 608.2462\n",
      "iteration 27000, loss = 567.1561\n",
      "iteration 28000, loss = 529.0935\n",
      "iteration 29000, loss = 894.2861\n",
      "iteration 30000, loss = 459.8160\n",
      "iteration 31000, loss = 445.2917\n",
      "iteration 32000, loss = 423.9527\n",
      "iteration 33000, loss = 383.3915\n",
      "iteration 34000, loss = 369.7254\n",
      "iteration 35000, loss = 362.6263\n",
      "iteration 36000, loss = 414.5090\n",
      "iteration 37000, loss = 300.8961\n",
      "iteration 38000, loss = 290.8117\n",
      "iteration 39000, loss = 281.3746\n",
      "iteration 40000, loss = 375.5024\n",
      "iteration 41000, loss = 250.3557\n",
      "iteration 42000, loss = 254.2523\n",
      "iteration 43000, loss = 303.9760\n",
      "iteration 44000, loss = 233.8704\n",
      "iteration 45000, loss = 270.1680\n",
      "iteration 46000, loss = 208.0503\n",
      "iteration 47000, loss = 212.9368\n",
      "iteration 48000, loss = 191.8136\n",
      "iteration 49000, loss = 186.2614\n",
      "iteration 50000, loss = 193.8939\n",
      "iteration 51000, loss = 243.3942\n",
      "iteration 52000, loss = 172.8398\n",
      "iteration 53000, loss = 163.5859\n",
      "iteration 54000, loss = 161.3325\n",
      "iteration 55000, loss = 159.6360\n",
      "iteration 56000, loss = 148.8499\n",
      "iteration 57000, loss = 152.2698\n",
      "iteration 58000, loss = 150.3724\n",
      "iteration 59000, loss = 146.1066\n",
      "iteration 60000, loss = 176.4311\n",
      "iteration 61000, loss = 132.2417\n",
      "iteration 62000, loss = 133.3102\n",
      "iteration 63000, loss = 123.3069\n",
      "iteration 64000, loss = 116.6314\n",
      "iteration 65000, loss = 146.0675\n",
      "iteration 66000, loss = 130.6431\n",
      "iteration 67000, loss = 128.0605\n",
      "iteration 68000, loss = 114.1178\n",
      "iteration 69000, loss = 115.1314\n",
      "iteration 70000, loss = 104.0673\n",
      "iteration 71000, loss = 131.4187\n",
      "iteration 72000, loss = 105.4491\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/autodl-tmp/facial landmarks denoise/mask2mask.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bregion-8.seetacloud.com/root/autodl-tmp/facial%20landmarks%20denoise/mask2mask.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m zoptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bregion-8.seetacloud.com/root/autodl-tmp/facial%20landmarks%20denoise/mask2mask.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bregion-8.seetacloud.com/root/autodl-tmp/facial%20landmarks%20denoise/mask2mask.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m zoptimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bregion-8.seetacloud.com/root/autodl-tmp/facial%20landmarks%20denoise/mask2mask.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m xymodel\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bregion-8.seetacloud.com/root/autodl-tmp/facial%20landmarks%20denoise/mask2mask.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m mask\u001b[39m=\u001b[39mcreate_mask()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/optim/radam.py:118\u001b[0m, in \u001b[0;36mRAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[39m# record the step after step update\u001b[39;00m\n\u001b[1;32m    116\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 118\u001b[0m     F\u001b[39m.\u001b[39;49mradam(params_with_grad,\n\u001b[1;32m    119\u001b[0m             grads,\n\u001b[1;32m    120\u001b[0m             exp_avgs,\n\u001b[1;32m    121\u001b[0m             exp_avg_sqs,\n\u001b[1;32m    122\u001b[0m             state_steps,\n\u001b[1;32m    123\u001b[0m             beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    124\u001b[0m             beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    125\u001b[0m             lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    126\u001b[0m             weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    127\u001b[0m             eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    128\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/optim/_functional.py:457\u001b[0m, in \u001b[0;36mradam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, state_steps, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    456\u001b[0m exp_avg\u001b[39m.\u001b[39mmul_(beta1)\u001b[39m.\u001b[39madd_(grad, alpha\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta1)\n\u001b[0;32m--> 457\u001b[0m exp_avg_sq\u001b[39m.\u001b[39;49mmul_(beta2)\u001b[39m.\u001b[39;49maddcmul_(grad, grad, value\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m beta2)\n\u001b[1;32m    459\u001b[0m \u001b[39m# correcting bias for the first moving moment\u001b[39;00m\n\u001b[1;32m    460\u001b[0m bias_corrected_exp_avg \u001b[39m=\u001b[39m exp_avg \u001b[39m/\u001b[39m bias_correction1\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for itr in tnrange(500000):\n",
    "\tzmodel.train()\n",
    "\tmask=create_mask(channels=478)\n",
    "\tmask_inv=1-mask\n",
    "\tout=zmodel(noisyz*mask)\n",
    "\tloss=mse( out*mask_inv, noisyz*mask_inv)/mask_inv.sum()\n",
    "\tzoptimizer.zero_grad()\n",
    "\tloss.backward()\n",
    "\tzoptimizer.step()\n",
    "\n",
    "\txymodel.train()\n",
    "\tmask=create_mask()\n",
    "\tinput=noisyxy*mask\n",
    "\tout=xymodel(input)\t\t\n",
    "\tloss=mse( out, input)/mask.sum()\n",
    "\txyoptimizer.zero_grad()\n",
    "\tloss.backward()\n",
    "\txyoptimizer.step()\n",
    "\n",
    "\t#break\n",
    "\tif (itr+1)%1000 == 0:\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\txymodel.eval()\n",
    "\t\t\t\tzmodel.eval()\n",
    "\t\t\t\toutxy = xymodel(noisyxy).permute([1,0]).unflatten(1,(478,2))\n",
    "\t\t\t\toutz=zeros((30*30,478,1),device=device)\n",
    "\t\t\t\tfor j in range(100):\n",
    "\t\t\t\t\tmask=create_mask(channels=478)\n",
    "\t\t\t\t\toutz+=zmodel(noisyz*mask).permute([1,0]).unflatten(1,(478,1))\n",
    "\t\t\t\toutz/=100\n",
    "\t\t\t\tout=torch.cat((outxy,outz),dim=2)\n",
    "\t\t\t\tprint(\"iteration %d, loss = %.4f\" % (itr+1, loss.item()*100000))\n",
    "\t\t\t\twith open(f\"result/{str(itr+1)}.txt\",'w') as fp:\n",
    "\t\t\t\t\tfp.writelines(json.dumps(out.tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
