{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简介\n",
    "- [self2self](https://openaccess.thecvf.com/content_CVPR_2020/papers/Quan_Self2Self_With_Dropout_Learning_Self-Supervised_Denoising_From_Single_Image_CVPR_2020_paper.pdf)是利用单张图片就可以进行去噪\n",
    "- 利用伯努利采样得到的图片作为去噪网络输入伯努利采样的补集作为预测目标\n",
    "- 仅在伯努利采样补集上计算损失\n",
    "- 在伯努利采样概率0.3下运行100000次效果比较好\n",
    "- 论文中的网络结构使用了partial convolution和dropout，dropout比较关键\n",
    "- 掩码必须每个channel都不同效果才最好\n",
    "- 图片输入时调用toTensor即可，不要进行标准化\n",
    "- 不要使用randomFlip，不要使用多张图片，否则会破坏分布\n",
    "- 如何腐蚀noise图像是一个需要探讨的话题\n",
    "- L1 loss没有L2 loss抗噪，很容易出现彩块\n",
    "- 学习率不能过大，否则会很快学到噪声，并且adamw会梯度爆炸\n",
    "- 从雪坑的质感看，网络学到的近似于溶解\n",
    "- 加式残差学习在监督学习中效果很好，在无监督学习中起负面作用，直接加法的特点是高频特征学得很快，建议用拼接代替加法实现残差。\n",
    "- 神经网络对噪声的阻抗来自于伯努利抽样、池化层、cat操作\n",
    "- 采样概率过小或者过大都会加剧模糊\n",
    "- 第一层和最后一层的通道数对结果影响非常大，建议输入通道数至少达到64\n",
    "- 不用sigmoid函数图像会暗很多,清晰度也下降，但不管这样去噪后图片亮度都会偏暗\n",
    "- 倒数第二层通常是输入和输出通道数相同或使用cat作为输入的缓冲层，不使用激活函数，避免破坏输出分布，最后一层通常用sigmoid或者不使用激活函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "cuda\n",
      "d:\\project\\deep-learning\\unsupervised image denoise\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "import torchvision\n",
    "import os\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "\n",
    "print(torch.__version__)\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "if device=='cuda':\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "\n",
    "class HourGlassCNNBlock(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,p=0.3,dropout=False,activation=nn.LeakyReLU(0.1)):\n",
    "        super(HourGlassCNNBlock,self).__init__()\n",
    "        layers=[]\n",
    "        layers.append(nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1,device='cuda'))\n",
    "        if activation:layers.append(activation)\n",
    "        if dropout:layers.append(nn.Dropout2d(p))\n",
    "        self.main=nn.Sequential(*layers)\n",
    "    def forward(self,x):\n",
    "        return self.main(x)#channel不同不能进行残差学习\n",
    "\n",
    "class HourGlassCNN(nn.Module):\n",
    "    def __init__(self,p=0.3):\n",
    "        super(HourGlassCNN,self).__init__()\n",
    "        self.b1=HourGlassCNNBlock(3,32)\n",
    "        self.b2=HourGlassCNNBlock(32,64)\n",
    "        self.b3=HourGlassCNNBlock(64,128)\n",
    "        \n",
    "        self.b4=HourGlassCNNBlock(128,64,p)\n",
    "        self.b5=HourGlassCNNBlock(128,64,p)\n",
    "        self.b6=HourGlassCNNBlock(64,32,p)\n",
    "        self.b7=HourGlassCNNBlock(64,32,p)\n",
    "        self.b8=HourGlassCNNBlock(32,3,p,False,None)\n",
    "        self.b9=HourGlassCNNBlock(6,3,p,False,nn.Sigmoid())\n",
    "\n",
    "    def forward(self,x):\n",
    "        b1=self.b1(x)\n",
    "        b2=self.b2(b1)\n",
    "        b3=self.b3(b2)\n",
    "        b4=self.b4(b3)\n",
    "        \n",
    "        b5=self.b5(torch.cat((b4,b2),dim=1))\n",
    "        b6=self.b6(b5)\n",
    "        b7=self.b7(torch.cat((b6,b1),dim=1))\n",
    "        b8=self.b8(b7)\n",
    "        b9=self.b9(torch.cat((b8,x),dim=1))\n",
    "        return b9\n",
    "\n",
    "class Denoiser(nn.Module):\n",
    "    def __init__(self,p=0.3):\n",
    "        super(Denoiser,self).__init__()\n",
    "        self.main=HourGlassCNN(p=p)\n",
    "    def forward(self,x):\n",
    "        return self.main(x)\n",
    "\n",
    "import math\n",
    "from torch import tensor, cat, zeros, ones,  randperm, bernoulli, full\n",
    "from torch.nn.functional import conv2d\n",
    "\n",
    "\n",
    "# percent:percent of zeros in mask\n",
    "def create_mask(channels=3, height=512, width=512, percent=0.2, probability=0.25, mode='bernoulli', device='cuda'):\n",
    "    if mode == 'percent':\n",
    "        num = width*height*channels\n",
    "        num_zeros = math.floor(num*percent)\n",
    "        num_ones = num-num_zeros\n",
    "        x = cat((zeros(num_zeros, device=device), ones(num_ones, device=device)))\n",
    "        x = x[randperm(num)]\n",
    "        x = x.view((channels,height, width))\n",
    "        return x\n",
    "    elif mode == 'bernoulli':\n",
    "        return bernoulli(full((channels,height, width), 1-probability, device=device))\n",
    "\n",
    "\n",
    "def image_gradient(img, mode='scharr', device='cuda'):\n",
    "    if mode == 'weak':\n",
    "        kernel_x = tensor(data=[[0., 0., 0.], [0., -1., 1.], [0., 0., 0.]],\n",
    "                          device=device).repeat(3, 3, 1, 1)\n",
    "        kernel_y = tensor(data=[[0., 0., 0.], [0., -1., 0.], [0., 1., 0.]],\n",
    "                          device=device).repeat(3, 3, 1, 1)\n",
    "    elif mode == 'sobel':\n",
    "        kernel_x = tensor(data=[[-1., 0., 1.], [-2., 0., 2.], [-1., 0., 1.]],\n",
    "                          device=device).repeat(3, 3, 1, 1)/8\n",
    "        kernel_y = tensor(data=[[1., 2., 1.], [0., 0., 0.], [-1., -2., -1.]],\n",
    "                          device=device).repeat(3, 3, 1, 1)/8\n",
    "    elif mode == 'scharr':\n",
    "        kernel_x = tensor(data=[[-3., 0., 3.], [-10., 0., 10.], [-3., 0., 3.]],\n",
    "                          device=device).repeat(3, 3, 1, 1)/16\n",
    "        kernel_y = tensor(data=[[-3., -10., -3.], [0., 0., 0.], [3., 10., 3.]],\n",
    "                          device=device).repeat(3, 3, 1, 1)/16\n",
    "    dx = conv2d(img, weight=kernel_x, padding=1)\n",
    "    dy = conv2d(img, weight=kernel_y, padding=1)\n",
    "    return (dx**2+dy**2)**0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ae7318b7ba4c9386bcfcceda4d9c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "from tqdm.notebook import trange\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "def image_loader(image, device):\n",
    "\t\"\"\"load image, returns cuda tensor\"\"\"\n",
    "\tloader = ToTensor()\n",
    "\timage = loader(image).unsqueeze(0)\n",
    "\treturn image.to(device)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\tif torch.cuda.is_available():\n",
    "\t\tdevice = torch.device('cuda')\n",
    "\telse:\n",
    "\t\tdevice = torch.device('cpu')\n",
    "\t\n",
    "\tprint('using device:', device) \n",
    "\t\n",
    "\tmodel = Denoiser().to(device=device)\n",
    "\timg = Image.open(\"data/self2self_pytorch/examples/noisy.png\")\n",
    "\tnoisy=image_loader(img,device)\n",
    "\n",
    "\toptimizer = optim.Adam(model.parameters(),lr=1e-4)\n",
    "\n",
    "\tmse = nn.MSELoss(reduction='sum')\n",
    "\tfor itr in trange(500000):\n",
    "\t\tmodel.train()\n",
    "\t\tmask=create_mask()\n",
    "\t\tmask_inv=1-mask\n",
    "\t\tout=model(noisy*mask)\n",
    "\t\n",
    "\t\tloss=mse(out*mask_inv,noisy*mask_inv)/mask_inv.sum()\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t\n",
    "\t\t#break\n",
    "\t\tif (itr+1)%1000 == 0:\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tmodel.eval()\n",
    "\t\t\t\tout = torch.zeros((1,3,512,512),device=device)\n",
    "\t\t\t\tfor j in range(100):\n",
    "\t\t\t\t\tmask=create_mask()\n",
    "\t\t\t\t\tout+=model(noisy*mask)\n",
    "\t\t\t\tout/=100\n",
    "\t\t\t\tout=out.clip(0,1)\n",
    "\t\t\t\tprint(\"iteration %d, loss = %.4f\" % (itr+1, loss.item()*100))\n",
    "\t\t\t\tsave_image(out,\"images/self2self-\"+str(itr+1)+\".png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5d6a002194865cab5a4bec71c277f27d10bc8e4f07be28304c019a3736a4e23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
